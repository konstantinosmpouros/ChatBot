{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e4898d-792b-44ab-9033-6546991ac751",
   "metadata": {},
   "source": [
    "# ChatBot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145ad043-ce86-43fd-bd78-94139daff13f",
   "metadata": {},
   "source": [
    "> Konstantinos Mpouros <br>\n",
    "> Github: https://github.com/konstantinosmpouros <br>\n",
    "> Year: 2025 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a425f285-2b4e-48e8-95d9-44a95acaf316",
   "metadata": {},
   "source": [
    "This project focuses on building an intelligent chatbot capable of providing accurate and context-aware responses. Designed to simulate human-like conversations, the chatbot is versatile enough for applications such as customer support, personal assistants, or educational tools.  \n",
    "\n",
    "The project leverages state-of-the-art large language models (LLMs), offering the flexibility to choose between an open-source model from Hugging Face or GPT-4o. This dual approach ensures adaptability to different requirements, balancing performance, cost, and customization potential.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e17a95-7001-4c22-876d-80836e1ddd7b",
   "metadata": {},
   "source": [
    "## 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65c1bfe7-10f8-42af-bb21-3358484a4afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 13:04:25.448798: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-21 13:04:25.448856: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-21 13:04:25.451726: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-21 13:04:25.464127: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-21 13:04:26.277203: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import gc\n",
    "\n",
    "# Chatbot UI\n",
    "import gradio as gr\n",
    "\n",
    "# Chatbot implementation\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# RAG\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.schema import Document\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e818730-b47e-4abb-b620-c92353196256",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Chatbot Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f26ed0-c918-42d9-b511-b1ad8f34bfdc",
   "metadata": {},
   "source": [
    "* Load enviroment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "843c7930-e16a-4060-bd30-e9dc6eaaa641",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ['HUGGINGFACE_TOKEN'] = os.getenv('HUGGINGFACE_TOKEN')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b0ed07-ca5a-4281-8eba-7f2cf0395b8e",
   "metadata": {},
   "source": [
    "* Login to hugging face hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7337012c-265e-47b9-9c67-a240aae23273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/kostasbouros/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(token=os.getenv('HUGGINGFACE_TOKEN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023708ee-5a05-4606-ba99-e218c186c2fd",
   "metadata": {},
   "source": [
    "* Define initial prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc2eba1a-4890-4458-b840-5d4b3678ed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_prompts():\n",
    "    system_message = \"\"\"\n",
    "        You are a helpfull ai assistant for an airline company named Aegean. Your tasks are the following:\n",
    "            1. Provide customer service support to the user about Aegean policies, flights, services etc.\n",
    "            2. Answer only in english, brief and clear, understanding first what the user needs.\n",
    "            3. Be always polity and kind with any user! Always remember that you are made for customer support.\n",
    "            4. If the user asks you to answer about something non related to aegean company and the relevant customer support, answer kindly that you cant answer that.\n",
    "            5. If the user want you to execute a function call, answer only the JSON format and nothing more!! Nothing more!!\n",
    "        When starting the conversation, greet kindly the user and then proceed to the customer support.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25343f1-3ec4-499c-a8c3-12a49d48648b",
   "metadata": {},
   "source": [
    "* Define a method to add in the history the user prompt and the response of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14565883-70f8-4012-8cfe-e2e617b7538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_history(history, role, prompt):\n",
    "    history.append({'role': role, 'content': prompt})\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ac6bb-c0e8-4dbf-8889-b11c0010b097",
   "metadata": {},
   "source": [
    "* Define a function to remind in the model not to respond for other stuff exept those in the system message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf42f77-558b-48a2-82d9-1fa0d1bdaf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_remider():\n",
    "    prompt = \"\"\"\n",
    "        Remember, you are an ai assistant of the Aegean company providing customer support and answer only question that has to do with the company's info.\n",
    "        if the user want to know something different answer kindly that you cant help with topic not relevand to aegean.\n",
    "        Answer only in english, brief and clear. \n",
    "        If in order to answer to the user you need to call a function then respond only the JSON needed and nothing else!!\n",
    "        Never reposnd the name of the function you call or here is the JSON format.\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f234ea-a458-4499-90d8-f51b1f6b835a",
   "metadata": {},
   "source": [
    "* Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31144b03-ef80-4c09-9799-f25de8c45d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    try:\n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "        # Set quantization method\n",
    "        quant_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            bnb_4bit_quant_type=\"nf4\"\n",
    "        )\n",
    "        \n",
    "        # Load model\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                                     device_map=\"cuda\",\n",
    "                                                     quantization_config=quant_config)\n",
    "\n",
    "        return tokenizer, model\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(ex.args)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        return None, None       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193ebe6d-6b7a-4533-bb59-48171ed05cdc",
   "metadata": {},
   "source": [
    "* Define a method to chat with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea7e89d3-4e26-4d6a-a9f3-66a1e95de074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_response(tokenizer, model, history, prompt):\n",
    "    # Set up the message to be tokenized\n",
    "    add_to_history(history, role='user', prompt=prompt)\n",
    "    add_to_history(history, role='system', prompt=add_remider())\n",
    "    tokenized_message = tokenizer.apply_chat_template(history, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "    # Generate response\n",
    "    response = model.generate(tokenized_message, temperature=0.85, max_new_tokens=10000)\n",
    "    generated_tokens = response[0][len(tokenized_message[0]):]\n",
    "\n",
    "    # Decode response\n",
    "    output = tokenizer.decode(generated_tokens , skip_special_tokens=True)\n",
    "    if \"assistant\" in output:\n",
    "        output = output.split(\"assistant\", 1)[-1].strip()\n",
    "    history = add_to_history(history, role='assistant', prompt=output)\n",
    "\n",
    "    return output, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46bddeed-24e5-4c1d-84e2-ffb904c8fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(tokenizer, model, history, prompt):\n",
    "    llm_response(tokenizer, model, history, prompt)\n",
    "    print(history[-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b467b-4864-4553-a5ec-c3f7413d77bd",
   "metadata": {},
   "source": [
    "* Lets chat with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d20cb91e-5c69-4744-8873-035261b9379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = init_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bb6334e-de1d-4fd8-88cb-2003ecf72fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bcfee3c7d33409ab8fd731dd5e65aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer, model = load_model('meta-llama/Meta-Llama-3.1-8B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14db1336-94ea-4ab8-b503-d5238cb82b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "2024-12-25 14:33:29.845039: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-25 14:33:29.913850: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-25 14:33:29.936274: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-25 14:33:30.071907: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-25 14:33:30.941420: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Konstantinos! I'm an assistant for Aegean Airlines. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "chat(tokenizer, model, history, 'Hi!!, l am konstantinos, you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a77b6397-1f99-4d6f-a4da-4c9ea7c89422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name \"Aegean\" originates from the Aegean Sea, which is a significant body of water in Greece, surrounding many islands where the airline operates. This geographical connection reflects the airline's Greek roots and its primary service area.\n"
     ]
    }
   ],
   "source": [
    "chat(tokenizer, model, history, 'l would like to know where the name aegean come from!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ab5accf-5406-473f-8de5-70e17698358a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a reliable and reputable airline, Aegean has received numerous awards and accolades, including \"Best Regional Airline in Europe\" from the Air Transport Awards. We strive to provide excellent service and safe travels to our passengers. Would you like to know more about our services or routes?\n"
     ]
    }
   ],
   "source": [
    "chat(tokenizer, model, history, 'l would like to know if it a good company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ade6737-584f-4052-9378-b1d43a659776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm glad you found that information helpful, Konstantinos. If you're ready to move forward, what else would you like to know about Aegean Airlines? Our fleet, destinations, or something else?\n"
     ]
    }
   ],
   "source": [
    "chat(tokenizer, model, history, 'Ok thats some nice info!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f213dabf-2c8d-4036-8b96-462956c1fe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to help with Aegean-related topics, Konstantinos, but unfortunately, I'm not able to assist with football-related questions as it's not related to Aegean Airlines. If you'd like to know something about our flight routes, services, or more, I'd be happy to help.\n"
     ]
    }
   ],
   "source": [
    "chat(tokenizer, model, history, 'l would like to ask you about football actually, can you assist?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dba5d3ad-c9d1-45f7-9043-f836801dbfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panathinaikos is a well-known Greek sports club, but unfortunately, it's not directly related to Aegean Airlines. I'd be happy to help with a different question about Aegean Airlines, though. Perhaps you'd like to know about our partnership with Panathinaikos or any other Aegean-related topic?\n"
     ]
    }
   ],
   "source": [
    "chat(tokenizer, model, history, 'tell me about panathinaikos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf197677-0544-42e0-89a0-e505b6e58e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to clarify, but unfortunately, I still can't assist with information about Panathinaikos' football team. My expertise lies within Aegean Airlines, and I'd be happy to provide information on our routes, services, or more. If you'd like to know something about Aegean's partnership with a sports club, I could try to provide that information.\n"
     ]
    }
   ],
   "source": [
    "chat(tokenizer, model, history, 'l dont want that, l want to know about the football only pls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e458246-b0ce-4384-b0a6-eae8584869aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm afraid I'm not able to provide information about Panathinaikos, as it's not related to Aegean Airlines. My purpose is to assist with questions about Aegean Airlines, and I'd be happy to help with that. If you'd like to know something about our services, routes, or more, I'd be happy to help.\n"
     ]
    }
   ],
   "source": [
    "chat(tokenizer, model, history, 'l want to know more about panathinaikos not aegean pls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5705392-4b96-4a4a-b233-3da86085aba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, Konstantinos. I remember your name. How can I help you with an Aegean Airlines-related question now?\n"
     ]
    }
   ],
   "source": [
    "chat(tokenizer, model, history, 'ok but do you remember my name?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17a8835-7c55-4dc3-b74b-e7bcc53c9ce7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. UI Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dc43134d-b8b2-4dc0-8f51-02d099bed12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kostasbouros/.local/lib/python3.10/site-packages/gradio/components/chatbot.py:242: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63bb42b89d0d4ffdab7bf6cbb76fb125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7875\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7875/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your functions\n",
    "def gradio_chat(user_input, history):\n",
    "    if not tokenizer or not model:\n",
    "        return \"Model not loaded. Please check the configuration.\", history\n",
    "\n",
    "    response, history = llm_response(tokenizer, model, history, user_input)\n",
    "    chat_history = [\n",
    "        (entry[\"content\"], None) if entry[\"role\"] == \"user\" else (None, entry[\"content\"]) \n",
    "        for entry in history if entry[\"role\"] != \"system\"\n",
    "    ]\n",
    "    return chat_history, history\n",
    "\n",
    "with gr.Blocks() as chat_interface:\n",
    "    gr.Markdown(\"### Aegean AI Chat Assistant\", elem_id=\"title\")\n",
    "    \n",
    "    chatbot = gr.Chatbot()\n",
    "    user_input = gr.Textbox(label=\"Your Message\", placeholder=\"Type your message here...\", lines=1)\n",
    "    send_button = gr.Button(\"Send\")\n",
    "    \n",
    "    # Logic for handling user input\n",
    "    def handle_chat(input_text, history):\n",
    "        chat_output, updated_history = gradio_chat(input_text, history)\n",
    "        return chat_output, updated_history, \"\"\n",
    "\n",
    "    # Bind send button and text box to chat logic\n",
    "    send_button.click(handle_chat, inputs=[user_input, gr.State(history)], outputs=[chatbot, gr.State(history), user_input])\n",
    "    user_input.submit(handle_chat, inputs=[user_input, gr.State(history)], outputs=[chatbot, gr.State(history), user_input])\n",
    "\n",
    "# Load the model and initialize the chat history\n",
    "history = init_prompts()\n",
    "tokenizer, model = load_model('meta-llama/Meta-Llama-3.1-8B-Instruct')\n",
    "\n",
    "# Launch the Gradio interface\n",
    "chat_interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3ef31e-49ee-49ec-a58b-518bc91dc8cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Streaming Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c48e9c2-c9d3-4419-870d-5a6f228ee604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_response_stream(tokenizer, model, history, prompt):\n",
    "    # Set up the message to be tokenized\n",
    "    add_to_history(history, role='user', prompt=prompt)\n",
    "    add_to_history(history, role='system', prompt=add_remider())\n",
    "    tokenized_message = tokenizer.apply_chat_template(history, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "    # Generate the full response\n",
    "    response = model.generate(\n",
    "        tokenized_message,\n",
    "        temperature=0.85,\n",
    "        max_new_tokens=10000\n",
    "    )\n",
    "    generated_tokens = response[0][len(tokenized_message[0]):]\n",
    "\n",
    "    # Decode response and stream it\n",
    "    output = \"\"\n",
    "    for i, token_id in enumerate(generated_tokens):\n",
    "        if i > 3:\n",
    "            token_text = tokenizer.decode(token_id, skip_special_tokens=True)\n",
    "            output += token_text\n",
    "            yield token_text  # Stream each token back\n",
    "\n",
    "    # Once streaming is complete, add the full output to history\n",
    "    if \"assistant\" in output:\n",
    "        output = output.split(\"assistant\", 1)[-1].strip()\n",
    "    history = add_to_history(history, role='assistant', prompt=output)\n",
    "\n",
    "    # Return the final history (if needed)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "856ee5f7-a744-42c3-a9fc-7d15034b8e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41dcd6cbdef94da4af6a88e4074dda96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer, model = load_model('meta-llama/Meta-Llama-3.1-8B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31b906e2-f978-4d4f-8d6d-1c050054d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = init_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9fae9f3f-0a7e-40f7-98d5-4c38d86abce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "!\n",
      " Welcome\n",
      " to\n",
      " Ae\n",
      "ge\n",
      "an\n",
      " Airlines\n",
      ".\n",
      " How\n",
      " can\n",
      " I\n",
      " assist\n",
      " you\n",
      " today\n",
      "?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = 'hello!!'\n",
    "\n",
    "response = []\n",
    "for token in llm_response_stream(tokenizer, model, history, prompt):\n",
    "    response.append(token)\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38bf6de1-0ea5-444b-971e-4891e75f4c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " \"'d\",\n",
       " ' be',\n",
       " ' happy',\n",
       " ' to',\n",
       " ' tell',\n",
       " ' you',\n",
       " ' about',\n",
       " ' Ae',\n",
       " 'ge',\n",
       " 'an',\n",
       " ' Airlines',\n",
       " '!\\n\\n',\n",
       " 'A',\n",
       " 'e',\n",
       " 'ge',\n",
       " 'an',\n",
       " ' Airlines',\n",
       " ' is',\n",
       " ' a',\n",
       " ' Greek',\n",
       " ' airline',\n",
       " ' that',\n",
       " ' operates',\n",
       " ' a',\n",
       " ' fleet',\n",
       " ' of',\n",
       " ' modern',\n",
       " ' aircraft',\n",
       " ',',\n",
       " ' offering',\n",
       " ' scheduled',\n",
       " ' and',\n",
       " ' charter',\n",
       " ' flights',\n",
       " ' to',\n",
       " ' over',\n",
       " ' ',\n",
       " '150',\n",
       " ' destinations',\n",
       " ' in',\n",
       " ' Europe',\n",
       " ',',\n",
       " ' Asia',\n",
       " ',',\n",
       " ' and',\n",
       " ' the',\n",
       " ' Middle',\n",
       " ' East',\n",
       " '.',\n",
       " ' The',\n",
       " ' airline',\n",
       " ' is',\n",
       " ' headquartered',\n",
       " ' at',\n",
       " ' Athens',\n",
       " ' Ele',\n",
       " 'f',\n",
       " 'ther',\n",
       " 'ios',\n",
       " ' Ven',\n",
       " 'iz',\n",
       " 'el',\n",
       " 'os',\n",
       " ' International',\n",
       " ' Airport',\n",
       " ' and',\n",
       " ' has',\n",
       " ' a',\n",
       " ' strong',\n",
       " ' focus',\n",
       " ' on',\n",
       " ' customer',\n",
       " ' service',\n",
       " ' and',\n",
       " ' safety',\n",
       " '.\\n\\n',\n",
       " 'Would',\n",
       " ' you',\n",
       " ' like',\n",
       " ' to',\n",
       " ' know',\n",
       " ' something',\n",
       " ' specific',\n",
       " ' about',\n",
       " ' Ae',\n",
       " 'ge',\n",
       " 'an',\n",
       " ' Airlines',\n",
       " ',',\n",
       " ' such',\n",
       " ' as',\n",
       " ' our',\n",
       " ' history',\n",
       " ',',\n",
       " ' fleet',\n",
       " ',',\n",
       " ' or',\n",
       " ' destinations',\n",
       " '?',\n",
       " '']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'tell me now about aegean!!'\n",
    "\n",
    "response = []\n",
    "for token in llm_response_stream(tokenizer, model, history, prompt):\n",
    "    response.append(token)\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998d8bce-9b94-4608-a1ab-30aed8882ed4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. Streaming UI Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d0dacd5-6370-4553-a0ed-61afb30049c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d832257285e24b359544d8d4ea1fc6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kostasbouros/.local/lib/python3.10/site-packages/gradio/components/chatbot.py:242: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "models_available = {\n",
    "    'Llama 3.1': 'meta-llama/Meta-Llama-3.1-8B-Instruct',\n",
    "    'Gemma 2': 'google/gemma-2-9b-it'\n",
    "}\n",
    "\n",
    "# Load the model and initialize the chat history\n",
    "history = init_prompts()\n",
    "tokenizer, model = load_model(models_available[\"Llama 3.1\"])\n",
    "\n",
    "# Initialize a method for chatting with the LLM using streaming\n",
    "def gradio_chat_stream(user_input, history):\n",
    "    if not tokenizer or not model:\n",
    "        yield \"Model not loaded. Please check the configuration.\", history, \"\"\n",
    "        return\n",
    "\n",
    "    # Start streaming tokens from the model\n",
    "    stream = llm_response_stream(tokenizer, model, history, user_input)\n",
    "        \n",
    "    # Initialize the chat history for display\n",
    "    chat_history = [\n",
    "        (entry[\"content\"], None) if entry[\"role\"] == \"user\" else (None, entry[\"content\"]) \n",
    "        for entry in history if entry[\"role\"] != \"system\"\n",
    "    ]\n",
    "\n",
    "    # Add the user's input to the chat display\n",
    "    chat_history.append((user_input, None))\n",
    "    yield chat_history, history, \"\"  # Show the user's input immediately\n",
    "\n",
    "    # Stream the assistant's response token by token\n",
    "    assistant_response = \"\"\n",
    "    for token in stream:\n",
    "        assistant_response += token\n",
    "        chat_history[-1] = (user_input, assistant_response)  # Update the assistant's response in the last chat entry\n",
    "        yield chat_history, history, \"\"  # Update the chatbot dynamically\n",
    "\n",
    "    # Finalize the assistant's response in the chat history\n",
    "    chat_history[-1] = (user_input, assistant_response)\n",
    "    yield chat_history, history, \"\"  # Ensure the final state is displayed\n",
    "\n",
    "# Set the Gradio UI\n",
    "with gr.Blocks() as chat_interface:\n",
    "    # Title\n",
    "    gr.Markdown(\"### Aegean AI Chat Assistant\", elem_id=\"title\")\n",
    "\n",
    "    # Add a dropdown for selecting models\n",
    "    model_dropdown = gr.Dropdown(\n",
    "        label=\"Select Model\",\n",
    "        choices=list(models_available.keys()),\n",
    "        value=list(models_available.keys())[0],\n",
    "        interactive=True\n",
    "    )\n",
    "\n",
    "    # Chatbox, Input, Send Button\n",
    "    chatbot = gr.Chatbot()\n",
    "    user_input = gr.Textbox(label=\"Your Message\", placeholder=\"Type your message here...\", lines=1)\n",
    "    send_button = gr.Button(\"Send\")\n",
    "\n",
    "    # Bind send button and text box to chat logic\n",
    "    send_button.click(\n",
    "        gradio_chat_stream, \n",
    "        inputs=[user_input, gr.State(history)], \n",
    "        outputs=[chatbot, gr.State(history), user_input]\n",
    "    )\n",
    "    user_input.submit(\n",
    "        gradio_chat_stream, \n",
    "        inputs=[user_input, gr.State(history)], \n",
    "        outputs=[chatbot, gr.State(history), user_input]\n",
    "    )\n",
    "\n",
    "# Launch the Gradio interface\n",
    "chat_interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9a847f-4288-4fe6-9c0e-f1942e47e4fa",
   "metadata": {},
   "source": [
    "## 6. RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5add261-4692-49e3-858b-b42bd7c00d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "knowledge_base_dir = \"RAG/knowledge_base\"\n",
    "vector_store_dir   = \"RAG/vector_store\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45022515-3218-4b7e-8d70-1cb21e9a3420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab all PDF files in the directory\n",
    "pdf_files = [f for f in os.listdir(knowledge_base_dir) if f.lower().endswith(\".pdf\")]\n",
    "\n",
    "# This list will hold exactly 1 Document per PDF\n",
    "all_docs = []\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_path = os.path.join(knowledge_base_dir, pdf_file)\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load()  # This typically returns multiple Document objects (one per page)\n",
    "    \n",
    "    # Combine text from all pages into one big string\n",
    "    combined_text = \"\\n\".join(page.page_content for page in pages)\n",
    "    \n",
    "    # Create a single Document with all pages combined\n",
    "    single_doc = Document(\n",
    "        page_content=combined_text,\n",
    "        metadata={\"source\": pdf_file}  # or any other metadata\n",
    "    )\n",
    "    all_docs.append(single_doc)\n",
    "\n",
    "len(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7c5c775-87e7-4c4b-ae69-2f871b08ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OpenAI Embeddings \n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a255bdf-2d92-45de-b65e-d425f384d827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13250/2449357020.py:9: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    }
   ],
   "source": [
    "# Create or load a Chroma vector store using the documents and embeddings\n",
    "db = Chroma.from_documents(\n",
    "    documents=all_docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=vector_store_dir\n",
    ")\n",
    "\n",
    "# Persist the database to disk (so you don’t have to re-embed every time)\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83d7c735-ffb8-423b-9285-5ca6f9f4a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever from the vector store\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",   # or \"mmr\", \"similarity_score_threshold\", etc.\n",
    "    search_kwargs={\"k\": 2}     # number of chunks to retrieve\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a62fd129-7a1a-47fd-ad72-a60dbe0275f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chunk 1 ---\n",
      "DANIEL ANDERSON\n",
      "Java Software Engineer | Backend Development | Data Analytics\n",
      "\u00001\u0000\u0000234\u0000\u0000555\u00001234 danielanderson@gmailcom danielanderson.com San Jose, California\n",
      "SUMMARY\n",
      "With five years of experience in Java development and a zeal for backend innovation, I thrive in high-performance environments. My biggest achievement includes leading a project to develop a scalable microservices architecture, significantly improving operational efficiency. Proficient in Java, Kubernetes, PostgreSQL, and passionate about advancing the functionalities and reliability of tech products.\n",
      "EXPERIENCE\n",
      "Senior Java Software Engineer\n",
      "NexTech Solutions 06/2019 \u0000 Present  San Jose, California\n",
      "Implemented a scalable microservices architecture for a financial product, reducing server costs by 30% while handling a 200% increase in traffic.Led the development and optimization of critical financial applications, improving transaction processing speed by 15%.Streamlined continuous integration/continuous deployment \u0000CI/CD\u0000 pipelines, enhancing deployment frequency by 50% and reducing rollout times from 4 hours to under 30 minutes.Piloted a new real-time analytics feature, increasing customer engagement metrics by 40%.Collaborated with cross-functional teams to refine project specifications, resulting in product features that boosted customer satisfaction scores by 25%.Organized code reviews and mentoring sessions that fostered a culture of high code quality and led to a 20% reduction in critical bugs.\n",
      "Java Developer\n",
      "Innovative Web Services 04/2017 \u0000 05/2019  Santa Clara, California\n",
      "Developed custom APIs for client web applications, improving data retrieval speeds by 60%.Enhanced code base using Java best practices, which contributed to a robust platform with 99.9% uptime.Migrated legacy systems to modern Java frameworks, leading to a 15% decrease in memory usage and faster page load times.Spearheaded a peer programming initiative that improved team productivity and software quality.Co-authored a paper on Java optimization techniques, which was published in a reputable tech journal.\n",
      "Software Engineer\n",
      "Tech Pioneers Inc. 01/2015 \u0000 03/2017  Mountain View, California\n",
      "Contributed to the development of a multi-platform application, leading to a user base growth of 100,000\u0000 within the first year of release.Optimized core software algorithms, which enhanced performance by 35%.Led a project to integrate third-party services using Java, simplifying product offerings and increasing customer choice.Assisted in the research and development of a proprietary data analysis tool, which is now utilized company-wide.\n",
      "EDUCATION\n",
      "Master of Science in Software Engineering\n",
      "San Jose State University 01/2013 \u0000 01/2015  San Jose, California\n",
      "Bachelor of Science in Computer Science\n",
      "University of California, Davis 01/2008 \u0000 01/2012  Davis, California\n",
      "LANGUAGES\n",
      "English Native Spanish Intermediate\n",
      "PROJECTS\n",
      "Blockchain-Based Secure Messaging\n",
      "Contributed to the development of an open source secure messaging platform using blockchain technology. More at github.com/daniel-anderson/secure-messaging\n",
      "Custom Data Analytics Engine\n",
      "Developed a custom engine for data analytics in Java, focused on improving customer purchase pattern analysis. More at github.com/daniel-anderson/data-analytics-engine\n",
      "ACHIEVEMENTS\n",
      "Published Java Optimization Techniques\n",
      "Co-authored a paper on efficient Java coding practices and optimization techniques, which was published in the Journal of System Software.\n",
      "Lead Developer for Financial Microservices\n",
      "Recognized as the lead developer for a project that created high-impact microservices for a finance application, significantly increasing company revenue.\n",
      "Successful Legacy System Migration\n",
      "Headed the successful migration of a client’s legacy system to a modern Java framework, earning the 'Innovation Award' from the company.\n",
      "Keynote Speaker at JavaCon\n",
      "Invited as a keynote speaker at JavaCon to discuss the future of Java technologies and my contributions to performance improvements.\n",
      "SKILLS\n",
      "Java Microservices Kubernetes\n",
      "Docker\n",
      "Object-Oriented Programming \u0000OOP\u0000\n",
      "OpenAPI\n",
      "www.enhancv.com\n",
      "\n",
      "Powered by\n",
      "E  q \n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "k\n",
      "\n",
      "b\n",
      "\n",
      "\n",
      "--- Chunk 2 ---\n",
      "KIAN WOODS\n",
      "EXPERIENCED SOFTWARE ENGINEER\n",
      "CONTACT\n",
      "kianwoods@email.com\n",
      "(123) 456-7890\n",
      "Pittsburgh, PA\n",
      "LinkedIn\n",
      "EDUCATION\n",
      "Bachelor of Science\n",
      "Computer Science\n",
      "Carnegie Mellon University\n",
      "2013 - 2017\n",
      "Pittsburgh, PA\n",
      "SKILLS\n",
      "PyCharm\n",
      "Mercurial\n",
      "Ruby on Rails\n",
      "Microsoft SQL Server\n",
      "Google Cloud Platform\n",
      "PHPUnit\n",
      "OpenShift\n",
      "CircleCI\n",
      "C++\n",
      "PyTorch\n",
      "CERTIFICATIONS\n",
      "Certiﬁed Software\n",
      "Development Associate (IEEE)\n",
      "WORK EXPERIENCE\n",
      "Software Engineer\n",
      "Duolingo\n",
      "August 2020 - current / Pittsburgh, PA\n",
      "Optimized machine learning algorithms with a C++ library for a\n",
      "38% boost to the eﬃciency of language learning models.\n",
      "Employed PyTorch to develop and improve the AI-driven\n",
      "language pronunciation feedback system.\n",
      "Used PyCharm as the primary IDE to increase development\n",
      "eﬃciency for a 27% reduction in bug-ﬁxing time.\n",
      "Worked with data science team to integrate machine learning\n",
      "algorithms to improved language model accuracy.\n",
      "DevOps Engineer\n",
      "PNC Financial Services\n",
      "June 2017 - June 2020 / Pittsburgh, PA\n",
      "Streamlined deployment process by implementing CircleCI,\n",
      "reducing build times by 34% and increasing deployment\n",
      "frequency by 61%.\n",
      "Led a team to migrate the company's database from MySQL to\n",
      "Microsoft SQL and to decrease query times by 21%.\n",
      "Developed custom Mercurial hooks to enforce coding standards,\n",
      "reducing code review time by 13%.\n",
      "Improved software release pipeline security by automating\n",
      "vulnerability scanning and patching.\n",
      "Software Developer Intern\n",
      "Vanguard\n",
      "2016 - 2017 / Remote\n",
      "Assisted in refactoring C++ code, helping to cut maintenance by\n",
      "14% and improving app performance.\n",
      "Conducted code reviews under 2 senior developers.\n",
      "Helped migrate applications to AWS and Azure, which cut\n",
      "infrastructure costs by 12% and aided application availability.\n",
      "Built a custom notiﬁcation system with JavaScript and\n",
      "WebSocket, increasing user engagement by 23% and improving\n",
      "real-time communication capabilities.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Do you know any Daniel Anderson?\"\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Print out each retrieved chunk\n",
    "for i, doc in enumerate(retrieved_docs, start=1):\n",
    "    print(f\"--- Chunk {i} ---\")\n",
    "    print(doc.page_content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e38905a-5fe4-4ca0-b6f8-8006298e5295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chunk 1 ---\n",
      "GABRIEL BAKER\n",
      "Senior QA Engineer | Agile & Scrum Expert\n",
      "\u00001\u0000\u0000234\u0000\u0000555\u00001234 gabrielbaker@enhancv.com gabrielbaker.com\n",
      "Denver, Colorado\n",
      "SUMMARY\n",
      "With over 5 years of experience as a Senior QA Engineer, my strengths lie in Agile and Scrum methodologies, with a proven track record in optimizing test processes and effective defect documentation leading to high-quality software solutions.\n",
      "EXPERIENCE\n",
      "Senior QA Engineer\n",
      "TechSolutions Inc\n",
      "06/2020 \u0000 Present  Denver, Colorado\n",
      "Led a team of QA specialists in a high-velocity Agile environment, achieving a 25% reduction in regression testing time through optimized test plans.Authored comprehensive test cases and executed 1500\u0000 tests for mobile and web applications, achieving 98% coverage and under 0.1% escape defects.Improved defect identification by 30% by implementing a systematic approach to document software defects using Jira.Streamlined communication between developers and QA by initiating weekly sync-ups, resulting in a 20% faster resolution of critical bugs.Contributed to product design reviews, influencing feature priorities and timeline adjustments, ensuring a user-centric approach to product enhancements.Created detailed business requirement documents, leading to more targeted user stories and efficient sprint planning.\n",
      "QA Analyst\n",
      "Innovatech Solutions\n",
      "03/2018 \u0000 05/2020  Boulder, Colorado\n",
      "Executed 200\u0000 automated and manual test scenarios bi-weekly, resulting in a steady release cadence with less than 2% rollback incidents.Spearheaded the adoption of SQL Clients for database testing, leading to a 40% improvement in data validation accuracy.Oversaw UML diagram creation for new features, improving cross-functional team understanding of complex functionalities by 35%.Played a pivotal role in a significant update of a consumer-facing app, which led to a user satisfaction increase of 20%.Managed a rigorous negative testing program, identifying 500\u0000 potential fail points and proactively safeguarding user experience.\n",
      "Quality Assurance Specialist\n",
      "BrightTech\n",
      "01/2015 \u0000 02/2018  Colorado Springs, Colorado\n",
      "Designed test plans and scripts for 4 new software product lines, improving test coverage and efficiency by 15%.Drove an initiative for more rigorous usability testing, enhancing product intuitiveness and reducing support tickets by 25%.Implemented a new bug tracking system with Confluence integration, improving defect traceability and collaboration.Successfully identified and documented over 300 bugs within the first year, consistently meeting milestone deadlines.\n",
      "EDUCATION\n",
      "Master of Science in Software Engineering\n",
      "University of Colorado Boulder\n",
      "01/2012 \u0000 01/2014  Boulder, Colorado\n",
      "Bachelor of Science in Computer Science\n",
      "Colorado State University\n",
      "01/2007 \u0000 01/2011  Fort Collins, Colorado\n",
      "PROJECTS\n",
      "Open Source Accessibility Tester\n",
      "Contributed to the development of a tool for testing web accessibility, ensuring compliance with WCAG 2.1. The project is available at github.com/accessibility-tool\n",
      "Mobile App Performance Monitor\n",
      "Participated in creating an open-source tool to monitor and optimize mobile app performance, focusing on user experience. See the project at github.com/mobile-performance\n",
      "ACHIEVEMENTS\n",
      "Streamlined QA Processes\n",
      "Leadership in QA methodology overhaul resulted in a 30% efficiency gain in test execution cycles.\n",
      "Reduced Production Bugs by 40%\n",
      "My rigorous testing approach and meticulous defect documentation led to a 40% reduction in production bugs.\n",
      "Implemented Database Testing Standards\n",
      "Introduced comprehensive SQL-based database testing standards that improved data verification processes.\n",
      "Increased Test Coverage\n",
      "Initiated an update to the existing testing suite that expanded coverage by 20% within a single quarter.\n",
      "SKILLS\n",
      "Agile methodologies Scrum frameworks\n",
      "Test case creation Jira Confluence\n",
      "SQL\n",
      "COURSES\n",
      "Certified Scrum Master \u0000CSM\u0000\n",
      "Completed the Certified Scrum Master course to enhance Agile project management skills. Offered by Scrum Alliance.\n",
      "Advanced Software Testing Certification\n",
      "Gained in-depth knowledge of advanced testing techniques and strategies through this certification. Provided by ISTQB.\n",
      "www.enhancv.com\n",
      "\n",
      "Powered by\n",
      "E  q\n",
      "\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "&\n",
      "0\n",
      "\n",
      "b\n",
      "\n",
      "--- Chunk 2 ---\n",
      "JASMINE BELL\n",
      "Lead Software Engineer\n",
      "212-312-7001 jasmine.bell@gmail.com github.io/jasmine-bell\n",
      "Austin, TX\n",
      "SUMMARY\n",
      "Passionate Software Engineer with 10\u0000 years of experience in developing web applications and backend systems. Skilled at writing clear, concise code that is easy to maintain and troubleshoot. Experienced in working with both small and large teams across multiple projects and companies. Able to work independently of remote locations or in office environments as needed by the company.\n",
      "PROFESSIONAL EXPERIENCE\n",
      "Lead Software Engineer 2021 \u0000 Present\n",
      "Blackbaud Austin, TX\n",
      "Successfully converted whole project from python 2 to 3.8.0Scripted unique test plans, test scripts and processes to remove previously known redundancy by 40% and ensured predictable outcomesDeveloped a desktop application to automate database testing process, improved efficiency by 65%Automated process to create usage graphs, saving $500,000 / year & increasing accuracy\n",
      "Senior Software Engineer 2017 \u0000 2021\n",
      "Wayfair Austin, TX\n",
      "Moved the automation solution into a commercial software \u0000$60k/year)Designed and developed reusable software components which used in 3 different project with reducing development effort by 50%Re-engineered critical modules within a sprint to rely on a centralized library to optimize performance by 68%Rated with the best annual performance rating for all the years during my stint; given to top \u00005% employees\n",
      "Software Developer 2015 \u0000 2017\n",
      "Target Austin, TX\n",
      "Helped to increase the accuracy of the reporting systems by 4%Delivered configuration management tools to track server settings for performance testing which saved 25% of initial machine setupDeveloped monitor reports that are using in-memory cache, updating the data shown to the user every 1 secondOptimized customer resources and reduce turnaround time by 20%Performed root cause analysis for more than 10 issues to identify bugs and rolled out fixes to production within 24 hours\n",
      "Junior Software Engineer 2013 \u0000 2015\n",
      "Redﬁn Austin, TX\n",
      "Fueled additional revenue stream through responsive customer support, generating $18k in new license sales within first three weeks of new releaseImproved user interfaces by updating menus to be more intuitive, increasing sales by 5%Reduced the time by 75% to process 70,000 to 1, 00,000 instruments from 16\u0000 seconds to less than 4 seconds by redesigning the algorithmWrote optimized scripts for  data-heavy & processing heavy task automationSpearheaded the revamp of tech stack which resulted in 40% decrease in server costs\n",
      "EDUCATION\n",
      "Executive MBA, Engineering Management 2010 \u0000 2011\n",
      "The University of Arizona Tucson, AZ\n",
      "Bachelor of Science, Computer Science 2006 \u0000 2009\n",
      "North Carolina Wesleyan College Rocky Mount, NC\n",
      "ACHIEVEMENTS\n",
      "Spearheaded a $12M software project\n",
      "from design to distribution as a senior software engineer in a 12-people team\n",
      "30% improved query e\u0000ciency\n",
      "by designing and fully revising the two largest MySQL databases\n",
      "Coordinated a year-long release of a six-part platform project\n",
      "with marketing, BA, QA, and sales department.\n",
      "Chatbot implementation\n",
      "Developed a chatbot which helped customer to reduce costs by 240% in their customer service department\n",
      "SKILLS\n",
      "Tools\n",
      "Java C\u0000\u0000 Python Perl mySQL\n",
      "ASP.NET\n",
      "Operating Systems\n",
      "Unix  Solaris Linux  Windows\n",
      "STRENGTHS\n",
      "Gold Medalist\n",
      "Was awarded a gold medal for 5 years of consecutive excellence in academics \u00002005\u00002010\u0000\n",
      "Corporate Social Responsibility\n",
      "Volunteered in the CSR team for Amadeus, organized tuition platforms for the underprivileged. Designed confluence page for book drives, etc. \n",
      "www.enhancv.com\n",
      "\n",
      "Powered by\n",
      "E  q\n",
      "\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Do you know any Gabriel Baker?\"\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Print out each retrieved chunk\n",
    "for i, doc in enumerate(retrieved_docs, start=1):\n",
    "    print(f\"--- Chunk {i} ---\")\n",
    "    print(doc.page_content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57b75547-dd85-4c21-b6e0-107fd121a1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chunk 1 ---\n",
      "MICHELLE SANDERS\n",
      "Software Engineer | Full-Stack Developer\n",
      "michellesanders@gmail.com linkedin.com Houston, Texas\n",
      "SUMMARY\n",
      "Dedicated Software Engineer with over two years of experience, skilled in full-stack development and cloud computing. Managed several technical projects, significantly enhancing system performance. Most notable achievement includes winning a university-level hackathon and contributing to a high-profile product during an internship at Hewlett Packard Enterprise.\n",
      "EXPERIENCE\n",
      "Software Engineering Intern\n",
      "D a t e  p e r i o d\n",
      "Hewlett Packard Enterprise Houston, TX\n",
      "Worked on product development using a modern tech stack while following Agile methodologies.\n",
      "Contributed to the development of a key feature in a product, resulting in a 15% increase in user engagement.Improved system performance by 10% through optimization of existing code base.Assisted in the migration of part of the company's infrastructure to a cloud-based solution.\n",
      "Junior Software Engineer Present\n",
      "Baker Hughes, a GE company Houston, TX\n",
      "Collaborated with the development team to deliver cutting-edge software solutions.\n",
      "Designed and implemented a new software component, boosting system functionality by 20%.Maintained and updated the company's internal database leading to streamlined processing of information.Acted as the liaison between the engineering and project management teams, ensuring smooth communication and workflow.\n",
      "EDUCATION\n",
      "Bachelor of Science in Computer Science\n",
      "2016 \u0000 2020\n",
      "University of Houston Houston, Texas\n",
      "LANGUAGES\n",
      "English Native Spanish Proficient\n",
      "STRENGTHS\n",
      "Technical Project Management\n",
      "Successfully managed multiple academic software projects, exceeding project deadlines and delivering high standard results.\n",
      "Multilingual Communication\n",
      "Proficient in English and Spanish, aiding the enhancement of communication within diverse development teams.\n",
      "Team Leadership\n",
      "Led teams of up to 5 university students in various projects, effectively managing resources and meeting project goals.\n",
      "SKILLS\n",
      "Java Python C\u0000\u0000\n",
      "Agile Methodologies\n",
      "Full-Stack Development\n",
      "Cloud Computing\n",
      "Database Management\n",
      "CERTIFICATION\n",
      "Java Programming and Software Engineering Fundamentals\n",
      "Completed at Duke University via Coursera in 2019\n",
      "AWS Certiﬁed Cloud Practitioner\n",
      "Certified by AWS in 2020\n",
      "PASSIONS\n",
      "Coding Challenges\n",
      "I enjoy pushing my coding abilities by participating in various coding competitions and hackathons.\n",
      "www.enhancv.com\n",
      "\n",
      "Powered by\n",
      " q \n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "\n",
      "*\n",
      "\n",
      "G\n",
      "PASSIONS\n",
      "Fitness\n",
      "Maintaining physical health and wellness through regular workouts and yoga.\n",
      "www.enhancv.com\n",
      "\n",
      "Powered by\n",
      "G\n",
      "\n",
      "--- Chunk 2 ---\n",
      "LYSANDRA VEGA\n",
      "Software Engineer\n",
      "lysandrav@email.com (123) 456-7890 Indianapolis, IN\n",
      "LinkedIn\n",
      "CAREER OBJECTIVE\n",
      "New computer engineering graduate with strong problem-\n",
      "solving skills and a commitment to excellence, seeking a\n",
      "software engineer role at Salesforce. Excited to use my skill in\n",
      "Git and Python to support Salesforce's vision of helping\n",
      "companies connect with their customers in fresh ways.\n",
      "WORK EXPERIENCE\n",
      "Software Engineer Intern\n",
      "Infosys \n",
      "January 2022 - March 2023 Indianapolis, IN\n",
      "Used Visual Studio Code for effective code editing and\n",
      "debugging, increasing code quality by 18%.\n",
      "Integrated third-party APIs with Python to enhance app\n",
      "functionality and increase user satisfaction by 24%.\n",
      "Improved database performance by optimizing MySQL\n",
      "queries, boosting query response times by 11%.\n",
      "Streamlined the continuous integration and deployment\n",
      "(CI/CD) pipeline, reducing build times by 27%.\n",
      "Cut merge conﬂicts by 13% using Git for version control\n",
      "and collaboration.\n",
      "PROJECTS\n",
      "Academic Simulation Project\n",
      "Group Leader\n",
      "2019 - current\n",
      "Developed backup and recovery strategies for macOS,\n",
      "increasing data recovery speeds by 17%.\n",
      "Implemented efﬁcient MySQL database schemas and\n",
      "decreased data redundancy by 28%.\n",
      "Employed Django ORM to manage database interactions,\n",
      "streamlining and reducing development time by 19%.\n",
      "Collaborated with a team of 4 to ensure timely project\n",
      "delivery while adhering to best practices.\n",
      "EDUCATION\n",
      "B.S.\n",
      "Computer Engineering\n",
      "Purdue University\n",
      "September 2019 - April 2023\n",
      "West Lafayette, IN\n",
      "SKILLS\n",
      "Visual Studio Code\n",
      "Git\n",
      "MySQL\n",
      "Django\n",
      "Heroku\n",
      "macOS\n",
      "Python\n",
      "CERTIFICATIONS\n",
      "Certiﬁed Software Development\n",
      "Professional (CSDP)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Do you know any Michelle Sanders?\"\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Print out each retrieved chunk\n",
    "for i, doc in enumerate(retrieved_docs, start=1):\n",
    "    print(f\"--- Chunk {i} ---\")\n",
    "    print(doc.page_content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a2988a5-8ff3-41f4-afe5-a27a30c7fd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chunk 1 ---\n",
      "First LastSoftware Engineer\n",
      "WORK EXPERIENCE\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ Resume Worded, London, United KingdomEducation technology startup with 50+ employees and $100m+ annual revenueSoftware Engineer 08/2021 – Present\n",
      "● Created an innovative feature in the company’s ﬂagship product that enabled50+ HNIs to purchase licenses simultaneously, increasing 2021 Q1 earningsby 71%.● Designed new applications by studying users' needs and converting theminto 20+ software programs.● Invented a RESTful API with Flask/Python in addition to an SQLAlchemy ORMlayer, enabling 2800+ developers to access data without exposingpasswords.● Developed applets for Resume Search Engine that provides 13K users withthe information on the search results page.\n",
      "Polyhire, London, United KingdomNYSE-listed recruitment and employer branding companyTest Engineer 10/2019 – 07/2021\n",
      "● Promoted continuous iteration of development and testing throughout theSDLC in collaboration with 20+ cross-functional team members.● Provided technical support in installing Cold Fusion, NetWare® WorkstationClient-Server Edition (WSCSE), and 20+ other database components.● Brainstormed with 10+ management and 30+ project team members tocoordinate QA per project schedules and business goals.● Detected and reported a ﬂaw in the mobile application of 90+ banks thatprevented an $850K loss; received an early promotion from executivemanagement.\n",
      "Growthsi, London, United Kingdom & Barcelona, SpainCareer training and membership SaaS with 150,000 usersTechnical Support Engineer 11/2018 – 09/2019\n",
      "● Identiﬁed patterns in customer complaints by keeping accurate records oftechnical support issues, helping to generate 50+ solutions for futureimprovements.● Developed a Standard Operating Procedure (SOP) for PC repair in the ITdepartment, reducing downtime by 84%.● Assisted 450+ clients in solving computer hardware, software, andnetwork-related issues in the ﬁrst month of employment.● Fixed a networking problem by utilizing 20+ built-in diagnostic tools for portdiagnostics and analyzing fragmented signals via an oscilloscope.\n",
      "PREVIOUS EXPERIENCE\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      " Sales Engineer, ABC Company, London, UK 06/2017 –10/2018Security Analyst, XYZ Company, New York, USA 01/2016– 05/2017Technical Writer (Internship), ABC, New York, USA 07/2014 – 12/2015\n",
      "CONTACT\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      " •\n",
      "Bristol, United Kingdom•\n",
      "+44 1234567890•\n",
      "ﬁrst.last@gmail.com\n",
      "SKILLS\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      " Hard Skills:•\n",
      "Computer Programming•\n",
      "Software Testing•\n",
      "Debugging.•\n",
      "Computer Networking•\n",
      "Optimizing Code•\n",
      "Integration and Unit testing\n",
      "Techniques:•\n",
      "Web Development•\n",
      "IT Automation•\n",
      "Software Development LifeCycle\n",
      "Tools and Software:•\n",
      ".NET Framework•\n",
      "AngularJS•\n",
      "C++•\n",
      "Node.js\n",
      "Languages:•\n",
      "English (Native)•\n",
      "Romanian (Native)•\n",
      "Spanish (Conversational)\n",
      "EDUCATION\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ University of New YorkAssociate of ScienceComputer ProgrammingNew York City, New York10/2011 - 06/2014\n",
      "OTHER\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      " •\n",
      "Certiﬁed Software Engineer•\n",
      "Certiﬁed Secure SoftwareLifecycle Professional\n",
      "\n",
      "--- Chunk 2 ---\n",
      "JASMINE BELL\n",
      "Lead Software Engineer\n",
      "212-312-7001 jasmine.bell@gmail.com github.io/jasmine-bell\n",
      "Austin, TX\n",
      "SUMMARY\n",
      "Passionate Software Engineer with 10\u0000 years of experience in developing web applications and backend systems. Skilled at writing clear, concise code that is easy to maintain and troubleshoot. Experienced in working with both small and large teams across multiple projects and companies. Able to work independently of remote locations or in office environments as needed by the company.\n",
      "PROFESSIONAL EXPERIENCE\n",
      "Lead Software Engineer 2021 \u0000 Present\n",
      "Blackbaud Austin, TX\n",
      "Successfully converted whole project from python 2 to 3.8.0Scripted unique test plans, test scripts and processes to remove previously known redundancy by 40% and ensured predictable outcomesDeveloped a desktop application to automate database testing process, improved efficiency by 65%Automated process to create usage graphs, saving $500,000 / year & increasing accuracy\n",
      "Senior Software Engineer 2017 \u0000 2021\n",
      "Wayfair Austin, TX\n",
      "Moved the automation solution into a commercial software \u0000$60k/year)Designed and developed reusable software components which used in 3 different project with reducing development effort by 50%Re-engineered critical modules within a sprint to rely on a centralized library to optimize performance by 68%Rated with the best annual performance rating for all the years during my stint; given to top \u00005% employees\n",
      "Software Developer 2015 \u0000 2017\n",
      "Target Austin, TX\n",
      "Helped to increase the accuracy of the reporting systems by 4%Delivered configuration management tools to track server settings for performance testing which saved 25% of initial machine setupDeveloped monitor reports that are using in-memory cache, updating the data shown to the user every 1 secondOptimized customer resources and reduce turnaround time by 20%Performed root cause analysis for more than 10 issues to identify bugs and rolled out fixes to production within 24 hours\n",
      "Junior Software Engineer 2013 \u0000 2015\n",
      "Redﬁn Austin, TX\n",
      "Fueled additional revenue stream through responsive customer support, generating $18k in new license sales within first three weeks of new releaseImproved user interfaces by updating menus to be more intuitive, increasing sales by 5%Reduced the time by 75% to process 70,000 to 1, 00,000 instruments from 16\u0000 seconds to less than 4 seconds by redesigning the algorithmWrote optimized scripts for  data-heavy & processing heavy task automationSpearheaded the revamp of tech stack which resulted in 40% decrease in server costs\n",
      "EDUCATION\n",
      "Executive MBA, Engineering Management 2010 \u0000 2011\n",
      "The University of Arizona Tucson, AZ\n",
      "Bachelor of Science, Computer Science 2006 \u0000 2009\n",
      "North Carolina Wesleyan College Rocky Mount, NC\n",
      "ACHIEVEMENTS\n",
      "Spearheaded a $12M software project\n",
      "from design to distribution as a senior software engineer in a 12-people team\n",
      "30% improved query e\u0000ciency\n",
      "by designing and fully revising the two largest MySQL databases\n",
      "Coordinated a year-long release of a six-part platform project\n",
      "with marketing, BA, QA, and sales department.\n",
      "Chatbot implementation\n",
      "Developed a chatbot which helped customer to reduce costs by 240% in their customer service department\n",
      "SKILLS\n",
      "Tools\n",
      "Java C\u0000\u0000 Python Perl mySQL\n",
      "ASP.NET\n",
      "Operating Systems\n",
      "Unix  Solaris Linux  Windows\n",
      "STRENGTHS\n",
      "Gold Medalist\n",
      "Was awarded a gold medal for 5 years of consecutive excellence in academics \u00002005\u00002010\u0000\n",
      "Corporate Social Responsibility\n",
      "Volunteered in the CSR team for Amadeus, organized tuition platforms for the underprivileged. Designed confluence page for book drives, etc. \n",
      "www.enhancv.com\n",
      "\n",
      "Powered by\n",
      "E  q\n",
      "\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "•\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Tell me any software engineer with more than a year of experience?\"\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Print out each retrieved chunk\n",
    "for i, doc in enumerate(retrieved_docs, start=1):\n",
    "    print(f\"--- Chunk {i} ---\")\n",
    "    print(doc.page_content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17e496bc-c677-441f-8482-ec6ee344be42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chunk 1 ---\n",
      "ZARA GREENE\n",
      "SOFTWARE ENGINEERING MANAGER\n",
      "CONTACT\n",
      "zaragreen@email.com\n",
      "(123) 456-7890\n",
      "Mountain View, CA\n",
      "LinkedIn\n",
      "Github\n",
      "EDUCATION\n",
      "M.S.\n",
      "Computer Science with a\n",
      "concentration in Software\n",
      "Theory or Software Systems\n",
      "Stanford University\n",
      "2010 - 2012\n",
      "Stanford, CA\n",
      "B.S.\n",
      "Computer Science\n",
      "Carnegie Mellon University\n",
      "2006 - 2010\n",
      "Pittsburgh, PA\n",
      "SKILLS\n",
      "Eclipse\n",
      "Git\n",
      "Docker\n",
      "Amazon Web Services (AWS)\n",
      "Jenkins\n",
      "React.js\n",
      "MySQL\n",
      "Java\n",
      "CERTIFICATIONS\n",
      "AWS Certiﬁed Developer from\n",
      "Amazon Web Services\n",
      "WORK EXPERIENCE\n",
      "Software Engineering Manager\n",
      "Google LLC\n",
      "May 2019 - April 2023 / Mountain View, CA\n",
      "Boosted application performance by 23% through the strategic use of\n",
      "Docker for containerization and deployment.\n",
      "Enhanced CI/CD pipelines by integrating Jenkins, accelerating release\n",
      "cycles by 21%.\n",
      "Optimized data storage and retrieval with MySQL, contributing to a\n",
      "29% increase in database performance.\n",
      "Mentored 5 junior engineers on best practices, increasing their\n",
      "productivity and improving code quality.\n",
      "Improved application architecture using AWS Cloud Services,\n",
      "reducing server response times by 28%.\n",
      "Systems Analyst\n",
      "IBM\n",
      "October 2015 - April 2019 / Armonk, NY\n",
      "Developed custom system monitoring tools using Java, improving\n",
      "infrastructure stability by 29%.\n",
      "Implemented Git for version control and collaboration, reducing code\n",
      "conﬂicts by 15%.\n",
      "Led the migration of legacy systems to modern technology stacks,\n",
      "improving system performance by 28%.\n",
      "Enhanced website interface design with React.js, boosting click-\n",
      "through rates by 24%.\n",
      "Leveraged MySQL for data management and analysis, boosting\n",
      "database performance by 26%.\n",
      "IT Support Technician\n",
      "PNC Financial Services Group\n",
      "September 2012 - September 2015 / Pittsburgh, PA\n",
      "Resolved an average of 35 daily IT support tickets, resulting in a 28%\n",
      "increase in end-user satisfaction.\n",
      "Used remote desktop tools to provide timely and efﬁcient support,\n",
      "decreasing average ticket resolution time by 19%.\n",
      "Introduced a centralized knowledge base, reducing ticket escalation\n",
      "rates by 23%.\n",
      "Coordinated with vendors for timely hardware replacements and\n",
      "upgrades, improving equipment reliability.\n",
      "Provided ongoing IT support for remote workforce, improving\n",
      "productivity by 22%.\n",
      "\n",
      "--- Chunk 2 ---\n",
      "ARIA FISCHER\n",
      "Junior Software Engineer\n",
      "a.ﬁscher@email.com (123) 456-7890 Southﬁeld, MI\n",
      "linkedin.com\n",
      "WORK EXPERIENCE\n",
      "IT Support Technician\n",
      "Blue Cross Blue Shield of Michigan\n",
      "August 2020 - current Detroit, MI\n",
      "Implemented Azure DevOps and Azure Storage cloud solutions,\n",
      "increasing infrastructure efﬁciency by 13%.\n",
      "Migrated 54% of the organization's code repositories to Subversion\n",
      "(SVN) to streamline version control.\n",
      "Resolved 20+ instances of software license non-compliance, saving\n",
      "around $54,000 in potential ﬁnes and penalties.\n",
      "Automated 8 routine IT tasks using Selenium to free 11 hours of\n",
      "staff time on average per week.\n",
      "Technical Support Representative\n",
      "Comcast\n",
      "December 2017 - June 2020 Ann Arbor, MI\n",
      "Achieved a monthly customer satisfaction rating of 98%, ranking\n",
      "within the top 3% of Technical Support Representatives at Comcast.\n",
      "Upsold Comcast services to Xﬁnity Internet customers, generating\n",
      "$21,000+ in additional annual revenue.\n",
      "Contacted customers with scheduled maintenance updates,\n",
      "reducing incoming calls by 65% on average.\n",
      "Handled 50+ support calls per day, addressing customer concerns\n",
      "related to product features and technical issues.\n",
      "PROJECTS\n",
      "Developer\n",
      "StudySpot\n",
      "2015 - 2017\n",
      "Used React to create a seamless user interface on Android and iOS\n",
      "apps, doubling monthly downloads in 7 months.\n",
      "Implemented a code repository management system using\n",
      "Subversion, boosting code collaboration efﬁciency by 34%.\n",
      "Enforced secure data transfer protocols and encryption\n",
      "mechanisms and ensured user data remained protected.\n",
      "Introduced an analytics and reporting framework with Microsoft\n",
      "Azure, providing insights into user behavior and patterns.\n",
      "CAREER\n",
      "OBJECTIVE\n",
      "A seasoned IT professional passionate\n",
      "about software development, seeking a\n",
      "junior software engineer role at Bosch.\n",
      "Eager to apply my experience with\n",
      "Eclipse and C++ to create high-quality\n",
      "software products that contribute to the\n",
      "company's engineering efforts. \n",
      "EDUCATION\n",
      "Bachelor of Science\n",
      "Computer Science and Engineering\n",
      "University of Michigan\n",
      "2013 - 2017\n",
      "Ann Arbor, MI\n",
      "SKILLS\n",
      "Eclipse\n",
      "Subversion (SVN)\n",
      "C++\n",
      "React\n",
      "PostgreSQL\n",
      "Microsoft Azure\n",
      "Selenium\n",
      "CERTIFICATIONS\n",
      "Certiﬁed Software Development\n",
      "Professional (CSDP)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"I want to know about software engineers that know or has worked with docker!\"\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Print out each retrieved chunk\n",
    "for i, doc in enumerate(retrieved_docs, start=1):\n",
    "    print(f\"--- Chunk {i} ---\")\n",
    "    print(doc.page_content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3df441-0f8e-4813-9729-a1737f5465fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e532da01-0ee7-4209-be4b-cfd1aef74e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1220a007-bc6d-45d7-bda3-a16ec4f4b1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e92dc-0167-41a9-8dbb-8ada05914fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e574f112-99d2-4225-9c72-85f10af8695b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
